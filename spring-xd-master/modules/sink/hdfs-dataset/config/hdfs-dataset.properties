info.shortDescription = Ingests data into HDFS after serializing (in Avro or Parquet format) it.
options.fsUri.description = the URI to use to access the Hadoop FileSystem
options.fsUri.type = String
options.fsUri.default = ${spring.hadoop.fsUri}

options.batchSize.description = threshold in number of messages when file will be automatically flushed and rolled over
options.batchSize.type = long
options.batchSize.default = 10000

options.basePath.description = the base directory path where the files will be written in the Hadoop FileSystem
options.basePath.type = String
options.basePath.default = /xd

options.namespace.description = the sub-directory under the basePath where files will be written
options.namespace.type = String
options.namespace.default = ${xd.stream.name}

options.idleTimeout.description = idle timeout in milliseconds when Hadoop file resource is automatically closed
options.idleTimeout.type = long
options.idleTimeout.default = -1

options.allowNullValues.description = whether null property values are allowed, if set to true then schema will use UNION for each field
options.allowNullValues.type = boolean
options.allowNullValues.default = false

options.format.description = the format to use, valid options are avro and parquet
options.format.type = String
options.format.default = avro

options.partitionPath.description = the partition path strategy to use, a list of KiteSDK partition expressions separated by a '/' symbol
options.partitionPath.type = String
options.partitionPath.default =

options.writerCacheSize.description = the size of the cache to be used for partition writers (10 if omitted)
options.writerCacheSize.type = int
options.writerCacheSize.default = -1

options.compressionType.description = compression type name (snappy, deflate, bzip2 (avro only) or uncompressed)
options.compressionType.type = String
options.compressionType.default = snappy
